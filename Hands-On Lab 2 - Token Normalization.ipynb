{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7657f7",
   "metadata": {},
   "source": [
    "## Hands-On Lab 2 - Token Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27f1c7",
   "metadata": {},
   "source": [
    "In this lab you will build on your tokenization skills by normalizing tokens from the *hotel reviews* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6598b",
   "metadata": {},
   "source": [
    "### Step 1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7659b",
   "metadata": {},
   "source": [
    "The *hotel reviews* data is stored as CSV file located within the *HotelReviews.zip* file. The *read_csv()* function from the *pandas* library will automatically load the CSV data from the ZIP file. Run the following code cell to load the data and display info about the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a76f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hotel_reviews = pd.read_csv('HotelReviews.zip')\n",
    "hotel_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df628940",
   "metadata": {},
   "source": [
    "### Step 2 - Loading English Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163f114",
   "metadata": {},
   "source": [
    "The NLTK comes with an extensive list of stopwords for the English language. Before using any stopword list, you should inspect it to make sure it applies to your domain. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4137a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce0448",
   "metadata": {},
   "source": [
    "### Step 3 - Customize Stopwords List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865f721",
   "metadata": {},
   "source": [
    "Customizing a stopwords list for a domain is a best practice. Given the *hotel reviews* dataset, removing some of the stopwords is a good idea. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2caba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83685b",
   "metadata": {},
   "source": [
    "### Step 4 - Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdadeb39",
   "metadata": {},
   "source": [
    "From Lab 1 you know that the *hotel reviews* documents have alread been folded to lower case. Time to tokenize the corpus and remove all stop words. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf28ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03fa84",
   "metadata": {},
   "source": [
    "### Step 5 - Stemming Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc11e7a",
   "metadata": {},
   "source": [
    "As you will learn later in the course, classes from the scikit-learn library can produce n-grams automatically from stemmed unigrams. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3392f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cedc5f",
   "metadata": {},
   "source": [
    "### Step 6 - Mapping POS Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c34a7f",
   "metadata": {},
   "source": [
    "As discussed in lecture, lemmatization is more effective when part-of-speech (POS) tagging is provided for each token. The following function maps the NLTK's universal POS tagset to use in lemmatization. Type the following code into the blank code cell in your lab notebook and run it to create the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d88318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819c2c9",
   "metadata": {},
   "source": [
    "### Step 7 - Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a576c",
   "metadata": {},
   "source": [
    "Lemmatization typically works best when using complete sentences before stopword removal. As the *hotel reviews* dataset is hard to tokenize as sentences, you will use an entire review. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72733f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
