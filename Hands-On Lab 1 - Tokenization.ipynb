{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0765664d",
   "metadata": {},
   "source": [
    "## Hands-On Lab 1 - Tokenization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052cc83",
   "metadata": {},
   "source": [
    "In this lab you will build practical tokenization skills using the *NLTK* library with the *hotel reviews* dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4dff9",
   "metadata": {},
   "source": [
    "### Step 1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82201061",
   "metadata": {},
   "source": [
    "The *hotel reviews* data is stored as CSV file located within the *HotelReviews.zip* file. The *read_csv()* function from the *pandas* library will automatically load the CSV data from the ZIP file. Run the following code cell to load the data and display info about the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hotel_reviews = pd.read_csv('HotelReviews.zip')\n",
    "hotel_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109d47b",
   "metadata": {},
   "source": [
    "### Step 2 - Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ed90d",
   "metadata": {},
   "source": [
    "When working with textual data, it's always a good idea to get a sense of what the documents look like. Are the documents single sentences (e.g., sarcastic headlines)? Are the documents multi-sentence and lengthy (e.g., novels)? Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b98ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f148e2",
   "metadata": {},
   "source": [
    "### Step 3 - Basic Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942acdf",
   "metadata": {},
   "source": [
    "After inspecting the document data, performing some basic word tokenization is a good idea to gain further understanding of the documents. Type the following code into the blank code cell in your lab notebook and run it to produce the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfb15c",
   "metadata": {},
   "source": [
    "### Step 4 - Tokenize All Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df208163",
   "metadata": {},
   "source": [
    "The *word_tokenize()* function is designed to tokenize one document at a time. Tokenizing the entire *hotel reviews* dataset is easily accomplished via a loop. Type the following code into the blank code cell in your lab notebook and run it to produce the results.\n",
    "\n",
    "NOTE: Since you imported the *word_tokenize()* function in Step 3, you do not need to import it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc9c6b",
   "metadata": {},
   "source": [
    "### Step 5 - Sentence Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ba206",
   "metadata": {},
   "source": [
    "Techniques like part-of-speech (POS) tagging are more effective when they are applied to entire tokenized sentences. While quite effective most of the time, the *sent_tokenize()* function expects certain patterns in textual data. Unfortunately, the *hotel reviews* dataset does not comply with these patterns. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30896948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f690b5",
   "metadata": {},
   "source": [
    "### Step 6 - Bigrams as Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04a0d3",
   "metadata": {},
   "source": [
    "The *ngrams()* function returns a list of tuples by default. Producing all bigrams for the *hotel reviews* dataset is again easily accomplished via a loop. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1392d",
   "metadata": {},
   "source": [
    "### Step 7 - Bigrams as Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98ef9e",
   "metadata": {},
   "source": [
    "Working with bigram strings is often more convenient than working with tuples. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94bcdf",
   "metadata": {},
   "source": [
    "### Step 8 - All the N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e94fe",
   "metadata": {},
   "source": [
    "For some types of text analytics (e.g., clustering) it can be beneficial to combine all the n-grams for each document in the corpus. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
