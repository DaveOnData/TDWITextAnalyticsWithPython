{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c151a1fe",
   "metadata": {},
   "source": [
    "## Hands-On Lab 5 - Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5348c60",
   "metadata": {},
   "source": [
    "### Step 1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4495a",
   "metadata": {},
   "source": [
    "The *hotel reviews* data is stored as CSV file located within the *HotelReviews.zip* file. The *read_csv()* function from the *pandas* library will automatically load the CSV data from the ZIP file. Run the following code cell to load the data and display info about the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307cc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hotel_reviews = pd.read_csv('HotelReviews.zip')\n",
    "hotel_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f916e",
   "metadata": {},
   "source": [
    "### Step 2 - Custom Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9134ae1",
   "metadata": {},
   "source": [
    "As discussed during lecture, the scikit-learn library classes provide extension points for using custom tokenization. The following code instantiates a global stopword list and Snowball stemmer so they are only created one time. Type the following code into the blank code cell in your lab notebook and run it to create the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df131d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a1462",
   "metadata": {},
   "source": [
    "### Step 3 - Custom Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748d091",
   "metadata": {},
   "source": [
    "The following function defines the NLTK-based custom tokenization and creates a document-term matrix using the custom tokenizer. As discussed during lecture, the naive Bayes algorithm is typically used with token counts as opposed to TF-IDF. Type the following code into the blank code cell in your lab notebook and run it to create the function and produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8fea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55130209",
   "metadata": {},
   "source": [
    "### Step 4 - Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfb7af",
   "metadata": {},
   "source": [
    "As discussed in lecture, the naive Bayes algorithm is simple to understand, simple to train, and is surprisingly effective in classifying documents (e.g., email spam filtering). In this lab you will train a naive Bayes model to predict whether a reivew is positive (i.e., a rating of 4 or 5). Type the following code into the blank code cell in your lab notebook and run it to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c0f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110cd449",
   "metadata": {},
   "source": [
    "### Step 5 - Tokenize the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3e335",
   "metadata": {},
   "source": [
    "Before predictions can be made, the test data needs to be tokenized in the same way the training data was tokenized. This ensures the vocabulary of the test data is the same as that of the training data. This is accomplished by reusing the CountVectorizer object. Type the following code into the blank code cell in your lab notebook and run it to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a89e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021c193",
   "metadata": {},
   "source": [
    "### Step 6 - Make Predictions and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2856cc",
   "metadata": {},
   "source": [
    "When classifying documents, you want some idea of how effective the predictive model will be when faced with new, unseen data. Using a test set allows you to simulate this scenario and estimate how effective the model will be. Type the following code into the blank code cell in your lab notebook and run it to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c3d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
